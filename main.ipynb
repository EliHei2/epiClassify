{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from synthetic import generate_dataset\n",
    "from MLP import MLP_classifier\n",
    "from GNN import GNN_classifier\n",
    "from graphs import convert_graph_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a synthetic dataset\n",
    "\n",
    "Current generative process:\n",
    "* For each feature, draw from a Gaussian with mean 0 and variance 1, and take the absolute value.\n",
    "* Each class is defined by 3 characteristic features. For each characteristic feature, the value \"signal\" is added.\n",
    "* Normalize the features\n",
    "* Diffuse the values through the graph: for each edge (a,b), the value $x_{a}$ of a is decreased by $\\text{diffusion_coefficient} \\times x_{a}/\\text{degree}(a)$ and the value of b is increased by the same amount.\n",
    "* Add an additional gaussian noise with mean 0 and variance \"noise\" on top of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 500 # per class\n",
    "n_features = 100\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a synthetic dataset and split between train and test\n",
    "X,y,graph = generate_dataset(n_classes,n_obs,n_features,nb_edges=3,nb_characteristic_features=3, \\\n",
    "                             signal=1.0,diffusion_coefficient=0.5,model=\"ER\",noise=0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test a fully-connected MLP\n",
    "\n",
    "Note: Actually, just use a perceptron for now, because it performs better than MLPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch DataLoader\n",
    "\n",
    "tensor_x_train = torch.Tensor(X_train).float()\n",
    "tensor_x_test = torch.Tensor(X_test).float()\n",
    "tensor_y_train = torch.Tensor(y_train).long()\n",
    "tensor_y_test = torch.Tensor(y_test).long()\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x_train,tensor_y_train) \n",
    "test_dataset = TensorDataset(tensor_x_test,tensor_y_test) \n",
    "train_dataloader = DataLoader(train_dataset,shuffle=True,batch_size=32) \n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLP_classifier(n_features=n_features,n_classes=n_classes,n_layers=1) #n_layers=1: just a perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.090\n",
      "[81] loss: 0.697\n",
      "[161] loss: 0.614\n",
      "[241] loss: 0.579\n",
      "[321] loss: 0.559\n",
      "[401] loss: 0.547\n",
      "[481] loss: 0.539\n",
      "[561] loss: 0.532\n",
      "[641] loss: 0.528\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(train_dataloader,epochs=800,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval(test_dataloader,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test a GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a graph dataset\n",
    "\n",
    "train_dataloader = convert_graph_dataset(graph,X_train,y_train)\n",
    "test_dataloader = convert_graph_dataset(graph,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GNN_classifier(n_features=n_features,n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(train_dataloader,epochs=150,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval(test_dataloader,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
